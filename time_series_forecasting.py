# -*- coding: utf-8 -*-
"""Time Series Forecasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bACqJ-T_Ru5K3x4Zjnj3EgmQ5QncTFPu

# **Predictive Analythic Nilai Tukar Mata Uang USD to IDR (Time Series / Forecasting)**

## **Objective:**   
Membangun sebuah model Machine Learning yang dapat memprediksi nilai tukar mata uang USD ke IDR per tanggal.

## **Sumber Dataset**
https://finance.yahoo.com/quote/USDIDR=X/history

# **Import Library**
"""

!pip install numpy==1.23.5
!pip install pmdarima==2.0.3
!pip install tensorflow==2.12.0

# Pengambilan dan manipulasi data
import yfinance as yf
import pandas as pd
import numpy as np

# Visualisasi
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

# Modeling statistik
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller
import pmdarima as pm

# Deep Learning
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Untuk menyimpan model
import joblib

"""# **Data Loading**"""

import yfinance as yf

# Download dari tahun 2020 sampai sekarang
data = yf.download('USDIDR=X', start='2000-01-01', end='2025-05-01')

# 3. Simpan sebagai CSV
data.to_csv('usd_to_idr.csv')

# Tampilkan data awal
data

"""Terdapat 6010 data (baris), dengan 5 kolom (Close, High, Low, Open, dan Volume) serta 1 kolom DatetimeIndex (date)

# **Exploratory Data Analysis**

## **Deskripsi Variabel**

* **Date**:	Tanggal pencatatan data nilai tukar
* **Open**:	Kurs saat pembukaan pasar pada hari tersebut
* **High**:	Kurs tertinggi selama hari tersebut
* **Low**:	Kurs terendah selama hari tersebut
* **Close**:	Kurs saat penutupan pasar pada hari tersebut
* **Volume**:	Jumlah volume transaksi yang terjadi pada hari tersebut (sering 0 untuk kurs karena bukan saham dan tidak akan digunakan)
* **Ticker**:	Kode unik dari data instrumen — di sini USDIDR=X artinya USD ke IDR
"""

data.info()

"""* Terdapat kolom khusus yang diindeks berdasarkan tanggal dengan tipe DatetimeIndex (dari 2001-06-28 hingga 2025-04-30)
* Terdapat 4 kolom numerik dengan tipe data float64, yaitu: Close, High, Low, dan Open. Kolom ini merupakan categorical features (fitur non-numerik). Ini merupakan fitur numerik yang menunjukkan nilai Tukar uang USD ke IDR.
* Terdapat 1 kolom numerik dengan tipe data int64 yaitu Volume yaitu transaksi yang terjadi pada hari tersebut. Kolom ini nantinya akan dihapus pada tahap cleaning karena tidak akan digunakan.
"""

data.head()

data.describe()

"""* Count  adalah jumlah sampel pada data.
* Mean adalah nilai rata-rata.
* Std adalah standar deviasi.
* Min yaitu nilai minimum setiap kolom.
* 25% adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
* 50% adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
* 75% adalah kuartil ketiga.
* Max adalah nilai maksimum.

## **Menangani Duplikasi dan Missing Values**

### **Drop Unused Column 'Volume'**
"""

# menghapus kolom yang memiliki nilai null seluruhnya dan kolomnya tidak akan digunakan
data.drop(columns=['Volume'], inplace=True)

"""### **Drop Duplicated Data**"""

print(data.columns)

print("Missing values:", data.isnull().sum())
print("Duplikat:", data.duplicated().sum())

"""Tidak ada **missing values** tetapi terdapat **duplikasi** sebanyak 6 data yang terduplikat"""

# Menghapus duplikat berdasarkan semua kolom
data_cleaned = data[~data.duplicated()]

print("Duplikat setelah dibersihkan:", data_cleaned.duplicated().sum())

"""### **Set 'Close' Column as Target Column**

Set Kolom 'Close' sebagai Target dan Sederhanakan Kolom

Karena kita akan melakukan time series forecasting, kita cukup menggunakan satu kolom utama, yaitu Close (nilai tukar akhir per hari). Kita akan ubah multi-index menjadi kolom biasa
"""

# Ubah kolom MultiIndex menjadi single index
data_cleaned.columns = ['Close', 'High', 'Low', 'Open']

# Simpan hanya kolom Close dan ubah indeks ke kolom
data_ts = data_cleaned[['Close']].copy()
data_ts.reset_index(inplace=True)
data_ts.rename(columns={'Date': 'Tanggal'}, inplace=True)
data_ts.set_index('Tanggal', inplace=True)

data_ts.head()

"""## **Visualisasi**

### **Boxplot Check to detect outliers**
"""

sns.boxplot(x=data_ts['Close'])

"""### **Line chart Check to detect outliers**"""

import matplotlib.pyplot as plt

plt.figure(figsize=(15, 5))
plt.plot(data_ts.index, data_ts['Close'], label='USD to IDR')
plt.title('Kurs USD ke IDR (2001–2025)')
plt.xlabel('Tahun')
plt.ylabel('Nilai Tukar (IDR)')
plt.legend()
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Salin data agar aman
data_outlier = data_ts.copy()

# Hitung Q1 dan Q3
Q1 = data_outlier['Close'].quantile(0.25)
Q3 = data_outlier['Close'].quantile(0.75)
IQR = Q3 - Q1

# Tentukan batas bawah dan atas
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Tandai outlier
data_outlier['Outlier'] = ((data_outlier['Close'] < lower_bound) | (data_outlier['Close'] > upper_bound))

# Plot
plt.figure(figsize=(15, 5))
plt.plot(data_outlier.index, data_outlier['Close'], label='USD to IDR')
plt.scatter(data_outlier.index[data_outlier['Outlier']],
            data_outlier['Close'][data_outlier['Outlier']],
            color='red', label='Outliers', zorder=5)
plt.axhline(lower_bound, color='gray', linestyle='--', linewidth=1, label='Lower Bound')
plt.axhline(upper_bound, color='gray', linestyle='--', linewidth=1, label='Upper Bound')
plt.title('Deteksi Outlier Nilai Tukar USD ke IDR')
plt.xlabel('Tahun')
plt.ylabel('Nilai Tukar (IDR)')
plt.legend()
plt.grid(True)
plt.show()

"""Terlihat terdapat **2 Outlier** pada kisaran tahun 2011-2012

### **Drop/Delete Outliers**
"""

# Hapus data outlier dari data_ts dan menyalin ke dataframe baru 'data_ts_cleaned'
data_ts_cleaned = data_outlier[~data_outlier['Outlier']].copy()

plt.figure(figsize=(15, 5))
plt.plot(data_ts_cleaned.index, data_ts_cleaned['Close'], label='USD to IDR (Cleaned)', color='blue')
plt.title('Nilai Tukar USD ke IDR Setelah Pembersihan Outlier')
plt.xlabel('Tahun')
plt.ylabel('Nilai Tukar (IDR)')
plt.legend()
plt.grid(True)
plt.show()

data_ts_cleaned.describe()

"""# **Uji Stasioneritas dan Differencing**

Dalam analisis time series, kita sering bekerja dengan data yang memiliki pola musiman atau tren. Stasioneritas merujuk pada kondisi di mana statistik dari data seperti mean (rata-rata), variance (varians), dan autokorelasi tidak berubah seiring waktu. Artinya, distribusi data tetap konsisten di sepanjang waktu.

Ada dua jenis stasioneritas:

* Stasioneritas yang lemah: Ini berarti data memiliki mean dan variance yang konstan dan autokorelasi yang hanya tergantung pada jarak antar titik data, bukan waktu.
* Stasioneritas yang kuat: Di sini, data benar-benar tidak bergantung pada waktu.

Pada time series forecasting, kita sering membutuhkan data yang stasioner karena sebagian besar model (terutama model ARIMA) bekerja lebih baik pada data yang tidak memiliki tren jangka panjang atau fluktuasi musiman yang signifikan.Untuk itu, Uji Stasioneritas - ADF Test (Augmented Dickey-Fuller) merupakan salah satu cara untuk menguji apakah data stasioner adalah dengan menggunakan ADF Test (Augmented Dickey-Fuller Test). Ini adalah uji statistik yang menguji hipotesis:

* Hipotesis nol (null hypothesis): Data tidak stasioner, atau ada unit root dalam data (artinya ada tren atau pola musiman yang mempengaruhi).
* Hipotesis alternatif: Data stasioner.

Proses uji ADF:
* p-value yang lebih kecil dari 0.05 mengindikasikan bahwa kita menolak hipotesis nol (data stasioner).
* Jika p-value lebih besar dari 0.05, maka kita gagal menolak hipotesis nol (data tidak stasioner).

Jika data tidak stasioner, salah satu teknik yang sering digunakan untuk mengubah data menjadi stasioner adalah ***differencing***. ***Differencing*** adalah proses menghitung selisih antara nilai saat ini dan nilai sebelumnya dalam urutan waktu.

Differencing membantu menghilangkan tren dan musiman dalam data. Ada beberapa jenis differencing:

**Differencing sederhana**: Menghitung perbedaan antara nilai saat ini dan nilai sebelumnya.

𝑌
𝑡
′
=
𝑌
𝑡
−
𝑌
𝑡
−
1
Y
t
′
​
 =Y
t
​
 −Y
t−1
​

**Seasonal differencing**: Jika data memiliki pola musiman, kita bisa mengambil perbedaan antara nilai saat ini dan nilai pada periode musiman sebelumnya.

𝑌
𝑡
′
=
𝑌
𝑡
−
𝑌
𝑡
−
𝑠
Y
t
′
​
 =Y
t
​
 −Y
t−s
​

di mana
𝑠
s adalah panjang musim atau siklus musiman (misalnya, setiap 12 bulan).

Setelah melakukan differencing, kita bisa memeriksa kembali apakah data telah menjadi stasioner menggunakan ADF Test lagi. Jika sudah stasioner, kita bisa melanjutkan ke tahap pemodelan.
"""

from statsmodels.tsa.stattools import adfuller

result = adfuller(data_ts_cleaned['Close'].dropna())
print('ADF Statistic:', result[0])
print('p-value:', result[1])
for key, value in result[4].items():
    print(f'Critical Value {key}: {value}')

"""* ADF Statistic = -0.49
* p-value = 0.893

Karena p-value jauh di atas 0.05, dan ADF Statistic lebih besar dari nilai kritis 10%, maka:

**Kesimpulan**: Data belum stasioner.
"""

# First-order differencing
data_diff = data_ts_cleaned.diff().dropna()

# Visualisasi hasil differencing
plt.figure(figsize=(15, 5))
plt.plot(data_diff.index, data_diff['Close'], label='Differenced USD to IDR')
plt.title('Differenced Kurs USD ke IDR')
plt.xlabel('Tahun')
plt.ylabel('Δ Nilai Tukar')
plt.legend()
plt.grid(True)
plt.show()

# Melakukan ADF test lagi pada data yang sudah di-differencing
from statsmodels.tsa.stattools import adfuller

result_diff = adfuller(data_diff['Close'])
print('ADF Statistic:', result_diff[0])
print('p-value:', result_diff[1])
for key, value in result_diff[4].items():
    print(f'Critical Value {key}: {value}')

"""**Sebelum Differencing**
* ADF Statistic: -0.49
* p-value: 0.893 (> 0.05)

Kesimpulan:
Nilai ADF statistic lebih besar dari critical values → gagal tolak H₀
p-value > 0.05 → data tidak stasioner

**Setelah Differencing (First-Order)**
* ADF Statistic: -25.53
* p-value: 2.17 × 10⁻²⁸ (< 0.05)

Kesimpulan:
Nilai ADF statistic lebih kecil dari critical values → tolak H₀
p-value < 0.05 → sudah menjadi data stasioner

# **Modelling**
"""

from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
import matplotlib.pyplot as plt

# Menampilkan grafik ACF dan PACF
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plot_acf(data_diff['Close'], ax=plt.gca(), lags=30)
plt.title('ACF (q)')

plt.subplot(1, 2, 2)
plot_pacf(data_diff['Close'], ax=plt.gca(), lags=30, method='ywm')
plt.title('PACF (p)')

plt.tight_layout()
plt.show()

"""**Interpretasi Grafik ACF & PACF**

ACF (untuk menentukan nilai q)
* Grafik ACF (Autocorrelation Function) menunjukkan cut-off (pemutusan tajam) atau peluruhan lambat.
* ACF terlihat signifikan hanya pada lag 1, lalu amplitudo nilai-nilainya mengecil.
* Ini mengindikasikan q = 1 untuk bagian MA (Moving Average).

PACF (untuk menentukan nilai p)
* Grafik PACF (Partial Autocorrelation Function) menunjukkan pemutusan tajam setelah lag 1.
* Nilai PACF signifikan hanya pada lag 1, lalu mengecil pada lag berikutnya.
* Ini menunjukkan p = 1 untuk bagian AR (Autoregressive).

**Kesimpulan Awal**
* p = 1   (dari PACF)
* d = 1   (karena sudah dilakukan differencing satu kali)
* q = 1   (dari ACF)

## **Model 1 menggunakan ARIMA**
"""

from statsmodels.tsa.arima.model import ARIMA

model1_arima = ARIMA(data_ts_cleaned['Close'], order=(1,1,1))
model1_fit = model1_arima.fit()

print(model1_fit.summary())

"""**Interpretasi Hasil Model**

**Model summary**:

* ARIMA(1,1,1) berarti:
  * Orde 1 untuk autoregressive (AR)
  * Diferensiasi 1 (I) → untuk membuat data menjadi stasioner
  * Moving average (MA) orde 1

* AIC: 74391.445 — digunakan untuk membandingkan antar model, semakin kecil semakin baik.

* Koefisien:
  * ar.L1 = 0.2084 → pengaruh positif dari lag sebelumnya.
  * ma.L1 = -0.5631 → efek negatif dari error lag sebelumnya.

* sigma2 = 1.415e+04 → variansi dari noise model.

* Ljung-Box test (L1): Probabilitas 0.26 → tidak ada autocorrelation signifikan pada lag 1.

* JB test menunjukkan non-normalitas residual, dengan kurtosis sangat tinggi (104.15).

**Kesimpulan**: Model cukup baik menangani serial correlation, tapi residualnya heavy-tailed dan sangat non-normal.
"""

import statsmodels.api as sm
import matplotlib.pyplot as plt

# Plot residual
residuals = model1_fit.resid

# ACF plot residual
sm.graphics.tsa.plot_acf(residuals, lags=50)
plt.title("ACF dari Residual")
plt.show()

# Q-Q Plot
sm.qqplot(residuals, line='s')
plt.title("Q-Q Plot Residual")
plt.show()

# Histogram
plt.hist(residuals, bins=50)
plt.title("Distribusi Residual")
plt.show()

"""## **Model 2 menggunakan SARIMA**"""

from statsmodels.tsa.statespace.sarimax import SARIMAX

# Misal seasonality 12 bulan (s=12) dengan 1 lag musiman
model_sarima = SARIMAX(
    data_ts_cleaned['Close'],
    order=(3, 1, 1),
    seasonal_order=(1, 1, 1, 12),
    enforce_stationarity=False,
    enforce_invertibility=False
)
res_sarima = model_sarima.fit()
print(res_sarima.summary())

"""**Model summary**:

* Penambahan komponen musiman (seasonal) sangat penting di model ini.

* seasonal_order=(1,1,1,12) artinya ada efek musiman

* tahunan (12 periode = bulanan).

* AIC: 73905.181 → lebih rendah dari ARIMA → model ini lebih baik dari ARIMA.

* Koefisien signifikan semua, kecuali ar.S.L12 yang marginal (p ≈ 0.08).

* ma.S.L12 = -1.000 → model menangkap efek musiman dengan kuat.

* JB test dan Heteroskedastisitas test menunjukkan masih ada masalah pada residual.

**Kesimpulan**: Model ini menangkap pola musiman dengan baik, dan secara statistik lebih baik daripada ARIMA biasa (lihat AIC dan log-likelihood).

## **Model 3 menggunakan ARIMA-GARCH**
"""

!pip install arch

from statsmodels.tsa.arima.model import ARIMA

from arch import arch_model

# Pertama ambil residual ARIMA terbaik
residuals = model1_fit.resid #diambil dari model 1 ARIMAA

# Fit GARCH ke residual dari ARIMA
garch_model = arch_model(residuals, vol='GARCH', p=1, q=1)
garch_result = garch_model.fit(disp='off')

# Summary hasil GARCH
print(garch_result.summary())

"""**Model summary**:

* Digunakan untuk memodelkan volatilitas, cocok untuk data keuangan.

* Mean model: konstan (mu = 0.3756), tidak signifikan (p=0.673) → tidak banyak tren di mean.

* Variansi model (GARCH):

  * omega = 211.65 → base level volatilitas.

  * alpha[1] = 0.1703 → efek shock jangka pendek.

  * beta[1] = 0.8183 → efek persistensi volatilitas (tinggi → efek volatilitas bertahan lama).

* AIC: 68686.5 → jauh lebih rendah dari ARIMA/SARIMA → secara log-likelihood lebih fit.

**Kesimpulan**: Model sangat cocok untuk memprediksi volatilitas USD/IDR. Kombinasi GARCH dan ARIMA berguna untuk data keuangan yang heteroskedastik.

## **Model 4 Deep Learning LSTM**
"""

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

# Load dataset
# Gunakan data yang sudah dibersihkan
df = data_ts_cleaned[['Close']].copy()

# Normalisasi data
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df)

# Membuat sequence
def create_sequences(data, seq_length=30):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)

seq_length = 30
X, y = create_sequences(scaled_data, seq_length)

# Split data
split = int(0.8 * len(X))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

# Build LSTM
model = Sequential()
model.add(LSTM(50, input_shape=(seq_length, 1)))
model.add(Dense(1))
model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')

# Train
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
history = model.fit(X_train, y_train, validation_data=(X_test, y_test),
                    epochs=50, batch_size=32, callbacks=[early_stop], verbose=1)

# Predict and inverse scale
y_pred_scaled = model.predict(X_test)
y_pred = scaler.inverse_transform(y_pred_scaled)
y_test_true = scaler.inverse_transform(y_test.reshape(-1, 1))

# Plot
plt.figure(figsize=(10, 5))
plt.plot(y_test_true, label='Actual')
plt.plot(y_pred, label='Predicted')
plt.legend()
plt.title('LSTM Forecast vs Actual')
plt.show()

"""**Interpretasi**
* Garis biru (Actual) dan garis oranye (Predicted) hampir selalu berdekatan. Ini menunjukkan bahwa model LSTM berhasil menangkap pola tren dan fluktuasi dalam data historis nilai tukar USD/IDR.

* Fluktuasi musiman dan jangka pendek juga cukup akurat direplikasi oleh model.

* Tidak ada deviasi besar antara prediksi dan nilai aktual, artinya kesalahan prediksi relatif kecil.

* Tidak terlihat adanya overfitting atau underfitting yang ekstrem — prediksi mengikuti data aktual dengan halus tanpa noise yang berlebihan.

## **Evaluasi Model**

Evaluasi model dalam proyek machine learning/time series forecasting memiliki beberapa tujuan penting:

* **Mengukur Kinerja Model**
  * Mengetahui seberapa akurat model dalam memprediksi data yang belum pernah dilihat (data uji).
  * Contoh metrik: MAE (Mean Absolute Error), RMSE (Root Mean Squared Error), MAPE (Mean Absolute Percentage Error).

* **Membandingkan Beberapa Model**
  * Menentukan model terbaik dari beberapa alternatif

* **Menentukan Kelayakan Model untuk Deployment**
  * Jika error terlalu besar (misal MAPE > 10%), model mungkin tidak layak digunakan.

* **Memberikan Insight**
"""

# Evaluasi dengan Metrik Error
# (Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), dan Mean Absolute Percentage Error (MAPE).)

from sklearn.metrics import mean_absolute_error, mean_squared_error

def mean_absolute_percentage_error(y_true, y_pred):
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

# Membuat Dataset Uji (Test Set) yang lebih konsisten
split_index = int(0.8 * len(data_ts_cleaned))
test_actual = data_ts_cleaned['Close'].iloc[split_index:].values

# Evaluasi model 1 ARIMA

forecast_arima = model1_fit.forecast(steps=len(test_actual))

mae_arima = mean_absolute_error(test_actual, forecast_arima)
rmse_arima = np.sqrt(mean_squared_error(test_actual, forecast_arima))
mape_arima = mean_absolute_percentage_error(test_actual, forecast_arima)

# Evaluasi model 2 SARIMA

forecast_sarima = res_sarima.forecast(steps=len(test_actual))

mae_sarima = mean_absolute_error(test_actual, forecast_sarima)
rmse_sarima = np.sqrt(mean_squared_error(test_actual, forecast_sarima))
mape_sarima = mean_absolute_percentage_error(test_actual, forecast_sarima)

# Evaluasi model 3 ARIMA-GARCH

# Gunakan prediksi ARIMA, GARCH menambah value jika ingin modeling volatilitas
forecast_arima_garch = model1_fit.forecast(steps=len(test_actual))

mae_garch = mean_absolute_error(test_actual, forecast_arima_garch)
rmse_garch = np.sqrt(mean_squared_error(test_actual, forecast_arima_garch))
mape_garch = mean_absolute_percentage_error(test_actual, forecast_arima_garch)

# Evaluasi model 4 LSTM

mae_lstm = mean_absolute_error(y_test_true, y_pred)
rmse_lstm = np.sqrt(mean_squared_error(y_test_true, y_pred))
mape_lstm = mean_absolute_percentage_error(y_test_true, y_pred)

# Hasil Evaluasi

result_df = pd.DataFrame({
    'Model': ['ARIMA', 'SARIMA', 'ARIMA-GARCH', 'LSTM'],
    'MAE': [mae_arima, mae_sarima, mae_garch, mae_lstm],
    'RMSE': [rmse_arima, rmse_sarima, rmse_garch, rmse_lstm],
    'MAPE': [mape_arima, mape_sarima, mape_garch, mape_lstm]
})

print(result_df.sort_values(by='RMSE'))

"""**Interpretasi Evaluasi Model**

* LSTM: Kesalahan rata-rata hanya Rp65, fluktuasi ±Rp92, dan rata-rata persentase error 0.43 %—sangat rendah.
* ARIMA: Error ratusan hingga ribuan rupiah; MAPE 11 %.
* ARIMA-GARCH: Sama persis dengan ARIMA—GARCH tidak menambah akurasi forecast harga.
* SARIMA: Performanya paling buruk, error terbesar dan MAPE ~15 %.

**Kesimpulan**
* **Model terbaik**: LSTM, karena memberikan MAE, RMSE, dan MAPE paling rendah jauh di bawah model statistik klasik.
* ARIMA vs ARIMA-GARCH: identik, karena GARCH hanya menangani volatilitas (variance), bukan perbaikan langsung level prediksi harga.
* SARIMA kurang cocok — mungkin seasonal (tahunan) tidak terlalu kuat pada data harian nilai tukar ini.

# **Forecasting (Peramalan)**

Setelah menemukan model terbaik melalui evaluasi yang sudah dilakukan. Hal berikutnya adalah menguji akurasi atau performa model tersebut dengan Forecasting (Peramalan) untuk melihat prediksi yang dilakukan model dalam melihat situasi kedepannya.
"""

# Prediksi dengan model LSTM pada data uji
y_pred_scaled = model.predict(X_test)  # X_test adalah input data uji
y_pred = scaler.inverse_transform(y_pred_scaled)  # Mengembalikan skala ke nilai asli
y_test_true = scaler.inverse_transform(y_test.reshape(-1, 1))  # Nilai sebenarnya dari data uji

# Evaluasi model LSTM
mae_lstm = mean_absolute_error(y_test_true, y_pred)
rmse_lstm = np.sqrt(mean_squared_error(y_test_true, y_pred))
mape_lstm = mean_absolute_percentage_error(y_test_true, y_pred)

print(f"MAE: {mae_lstm}")
print(f"RMSE: {rmse_lstm}")
print(f"MAPE: {mape_lstm}")

# Plot hasil peramalan dan data asli
plt.figure(figsize=(10, 5))
plt.plot(y_test_true, label='Actual')
plt.plot(y_pred, label='Predicted')
plt.legend()
plt.title('LSTM Forecast vs Actual')
plt.show()

# Ambil data terakhir untuk memulai prediksi ke depan
last_sequence = scaled_data[-seq_length:]  # Sequence terakhir
last_sequence = last_sequence.reshape((1, seq_length, 1))  # Bentuk sesuai input LSTM

# Prediksi untuk 30 hari ke depan
forecast_steps = 100
forecast = []

for _ in range(forecast_steps):
    predicted_value = model.predict(last_sequence)
    forecast.append(predicted_value)

    # Update last_sequence untuk prediksi selanjutnya
    last_sequence = np.append(last_sequence[:, 1:, :], predicted_value.reshape(1, 1, 1), axis=1)

# Inverse transform hasil forecast
forecast = scaler.inverse_transform(np.array(forecast).reshape(-1, 1))

# Plot forecast untuk periode ke depan
plt.figure(figsize=(12,6))
plt.plot(np.arange(len(scaled_data)), scaler.inverse_transform(scaled_data), label='Actual', linewidth=2)
plt.plot(np.arange(len(scaled_data), len(scaled_data) + forecast_steps), forecast, label='Forecast', linestyle='--', linewidth=2)
plt.title('LSTM Forecast for Future')
plt.xlabel('Jumlah Pembaruan Data')
plt.ylabel('Nilai Tukar USD to IDR')
plt.legend()
plt.grid(True)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# 1. Ambil tanggal terakhir dari data asli
last_date = data_ts_cleaned.index[-1]

# 2. Buat range tanggal untuk hasil forecast
forecast_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=forecast_steps, freq='D')

# 3. Plot hasil forecast bersama data aktual
plt.figure(figsize=(14,6))
plt.plot(data_ts_cleaned.index, data_ts_cleaned['Close'], label='Actual', linewidth=2)
plt.plot(forecast_dates, forecast, label='Forecast', linestyle='--', linewidth=2, color='orange')

# 4. Perbaikan visualisasi
plt.title('LSTM Forecast for Future')
plt.xlabel('Tanggal')
plt.ylabel('Nilai Tukar USD to IDR')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd

# 1. Tentukan tanggal awal (hari setelah data terakhir)
last_date = data_ts_cleaned.index[-1]

# 2. Buat rangkaian tanggal harian sebanyak 30 hari ke depan
future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1),
                             periods=30,
                             freq='D')

# 3. Bentuk Series atau DataFrame
forecast_series = pd.Series(forecast.flatten(), index=future_dates, name='Predicted_Close')

forecast_df = forecast_series.reset_index().rename(columns={'index': 'Date'})
print(forecast_df)

"""# **Menyimpan Model dan Menguji Forecasting secara Dinamis**"""

# Simpan Model
model.save('lstm_model_forecasting.h5')
print("Model berhasil disimpan.")

# Menyimpan scaler
joblib.dump(scaler, 'scaler.pkl')
print("Scaler berhasil disimpan.")

import numpy as np
import matplotlib.pyplot as plt
import joblib
from tensorflow.keras.models import load_model

# Memuat model dan scaler yang sudah disimpan
model = load_model('lstm_model_forecasting.h5')
scaler = joblib.load('scaler.pkl')

# Fungsi untuk melakukan prediksi berdasarkan jumlah hari yang diinput oleh user
def forecast_for_days(days_ahead):
    # Ambil sequence terakhir dari data yang sudah dinormalisasi
    last_sequence = scaled_data[-seq_length:]  # Sequence terakhir
    last_sequence = last_sequence.reshape((1, seq_length, 1))  # Bentuk sesuai input LSTM

    forecast = []
    for _ in range(days_ahead):
        predicted_value = model.predict(last_sequence)
        forecast.append(predicted_value)

        # Update sequence untuk prediksi berikutnya
        last_sequence = np.append(last_sequence[:, 1:, :], predicted_value.reshape(1, 1, 1), axis=1)

    # Inverse transform hasil forecast
    forecast = scaler.inverse_transform(np.array(forecast).reshape(-1, 1))

    # Tanggal untuk prediksi berdasarkan hari ini
    last_date = data_ts_cleaned.index[-1]  # Tanggal terakhir dari data
    forecast_dates = pd.date_range(last_date, periods=days_ahead + 1, freq='D')[1:]

    # Menampilkan hasil forecast dan tanggal
    forecast_result = pd.DataFrame(forecast, index=forecast_dates, columns=['Predicted USD to IDR'])

    # Visualisasi hasil forecast
    plt.figure(figsize=(12, 6))
    plt.plot(data_ts_cleaned.index, scaler.inverse_transform(scaled_data), label='Actual', linewidth=2)
    plt.plot(forecast_result.index, forecast_result['Predicted USD to IDR'], label='Forecast', linestyle='--', linewidth=2)
    plt.title('Forecast for USD to IDR Exchange Rate')
    plt.xlabel('Date')
    plt.ylabel('USD to IDR Exchange Rate')
    plt.legend()
    plt.grid(True)
    plt.show()

    # Menampilkan hasil forecast untuk output
    print(f"Forecast for the next {days_ahead} days:")
    print(forecast_result)

# Meminta input dari user untuk jumlah hari yang ingin diprediksi
days_to_predict = int(input("Enter the number of days to forecast: "))
forecast_for_days(days_to_predict)
